{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Necessary libraries & modules are imported here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='Tokenizer.c' mode='r' encoding='cp1252'>\n"
     ]
    }
   ],
   "source": [
    "inputObject = open(\"Tokenizer.c\",\"r\")\n",
    "print(inputObject)\n",
    "inputString = inputObject.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking input string:\n",
    "#inputString = input(\"Enter code: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#include<stdio.h>\n",
      "//This is a demo code:\n",
      "int main()\n",
      "{\n",
      "    char str[100];\n",
      "\n",
      "    gets(str);\n",
      "\n",
      "    for(int i=0; ;i++)\n",
      "    {\n",
      "        if(str[i]=='\\0') { break; }\n",
      "\n",
      "\n",
      "    }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"#include<stdio.h>\\n//This is a demo code:\\nint main()\\n{\\n    char str[100];\\n\\n    gets(str);\\n\\n    for(int i=0; ;i++)\\n    {\\n        if(str[i]=='\\\\0') { break; }\\n\\n\\n    }\\n}\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(inputString)\n",
    "inputString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'Lexical Error: Identifiers cannot start with digits!')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_error = [(1,'Lexical Error: Identifiers cannot start with digits!')]\n",
    "list_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_digit = ['0','1','2','3','4','5','6','7','8','9']\n",
    "list_digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "list_letter = ['_','A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z',\n",
    "                 'a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "print(list_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_special_letter = ['d','f','c']\n",
    "#list_special_letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_special_char = ['%','&']\n",
    "#list_special_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['main', 'int', 'float', 'char', 'for', 'while', 'if', 'else', 'printf', 'scanf', 'return', 'include', 'define', 'break', 'gets', 'puts', 'auto', 'double', 'struct', 'long', 'switch', 'case', 'enum', 'register', 'typedef', 'extern', 'union', 'continue', 'signed', 'void', 'do', 'static', 'default', 'goto', 'sizeof', 'volatile', 'const', 'short', 'unsigned', 'NULL']\n"
     ]
    }
   ],
   "source": [
    "#dict_reserved = {'int':1,'float':2,'char':3,'for':4,'while':5,'if':6,'else if':7,'else':8,'printf':9,'scanf':10}\n",
    "list_reserved = ['main','int','float','char','for','while','if','else','printf','scanf','return',\n",
    "                 'include','define','break','gets','puts','auto','double','struct','long','switch',\n",
    "                 'case','enum','register','typedef','extern','union','continue','signed','void','do',\n",
    "                 'static','default','goto','sizeof','volatile','const','short','unsigned','NULL']\n",
    "print(list_reserved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#special_combination = ['\\n','\\t','']\n",
    "#special_combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_of_token = []\n",
    "stream_of_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_identifier = []\n",
    "list_identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_char_is_digit = False\n",
    "start_char_is_digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_is_float = False\n",
    "number_is_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_is_negative = False\n",
    "number_is_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_encountered = False\n",
    "error_encountered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scan_or_print_command = False\n",
    "scan_or_print_command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_is_set = False\n",
    "comment_is_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start_char_is_special = False\n",
    "#start_char_is_special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startingOperator = ''\n",
    "startingOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_lexeme = ''\n",
    "current_lexeme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_reserved_word(token):\n",
    "    print(\"Token=\",token)\n",
    "    if token in list_reserved:\n",
    "        current_token = ('KEYWORD',token)\n",
    "    else:\n",
    "        for value in list_identifier:\n",
    "            if token==value[1]: #If current identifier already exists...\n",
    "                current_token = ('id',value[0])\n",
    "                stream_of_token.append(current_token)\n",
    "                return\n",
    "            \n",
    "        num_id = len(list_identifier)\n",
    "        current_token = (num_id+1,token)\n",
    "        list_identifier.append(current_token)\n",
    "        current_token = ('id',num_id+1)\n",
    "        \n",
    "    stream_of_token.append(current_token)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_char_operator(op): \n",
    "    if op=='+':\n",
    "        cur_token = ('OP','PLUS')\n",
    "    elif op=='-':\n",
    "        cur_token = ('OP','MINUS')\n",
    "    elif op=='*':\n",
    "        cur_token = ('OP','MULTIPLY')\n",
    "    elif op=='/':\n",
    "        cur_token = ('OP','DIVIDE')\n",
    "    elif op=='^':\n",
    "        cur_token = ('OP','POWER')\n",
    "    elif op=='~':\n",
    "        cur_token = ('OP','NOT')\n",
    "    elif op=='%':\n",
    "        cur_token = ('OP','MODULO')\n",
    "    elif op=='<':\n",
    "        cur_token = ('OP','LESS_THAN')\n",
    "    elif op=='>':\n",
    "        cur_token = ('OP','GREATER_THAN')\n",
    "    elif op=='=':\n",
    "        cur_token = ('OP','ASSIGN')\n",
    "    elif op=='&':\n",
    "        cur_token = ('OP','ASSIGN_INPUT_VALUE_TO')\n",
    "        \n",
    "    stream_of_token.append(cur_token)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['+', '-', '*', '/', '=', '<', '>', '~', '%', '!', '^', '&', '|']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Necessary variables are declared here:\n",
    "list_operator = ['+','-','*','/','=','<','>','~','%','!','^','&','|']\n",
    "list_operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_char_operator(start_op,cur_op):\n",
    "    print(\"start_op= \"+start_op+\"; cur_op= \"+cur_op)\n",
    "    global number_is_negative, comment_is_set\n",
    "    cur_token = ''\n",
    "    \n",
    "    if start_op=='=' and cur_op=='=':\n",
    "        cur_token = ('OP','EQUAL')\n",
    "    elif start_op=='+' and cur_op=='=':\n",
    "        cur_token = ('OP','PLUS_EQUAL')\n",
    "    elif start_op=='-' and cur_op=='=':\n",
    "        cur_token = ('OP','MINUS_EQUAL')\n",
    "    elif start_op=='+' and cur_op=='+':\n",
    "        cur_token = ('OP','INCREAMENT')\n",
    "    elif start_op=='-' and cur_op=='-':\n",
    "        cur_token = ('OP','DECREAMENT')\n",
    "    elif start_op=='*' and cur_op=='=':\n",
    "        cur_token = ('OP','MULTIPLY_AND_ASSIGN')\n",
    "    elif start_op=='/' and cur_op=='=':\n",
    "        cur_token= ('OP','DIVIDE_AND_ASSIGN')\n",
    "    elif start_op=='<' and cur_op=='=':\n",
    "        cur_token = ('OP','LE')\n",
    "    elif start_op=='>' and cur_op=='=':\n",
    "        cur_token = ('OP','GE')\n",
    "    elif start_op=='!' and cur_op=='=':\n",
    "        cur_token = ('OP','NE')\n",
    "    elif start_op=='%' and cur_op=='=':\n",
    "        cur_token = ('OP','MODULO_AND_ASSIGN')\n",
    "    elif start_op=='-' and cur_op=='-':\n",
    "        cur_token = ('OP','DOUBLE_NEGATIVE')\n",
    "    elif start_op=='|' and cur_op=='|':\n",
    "        cur_token = ('OP','OR')\n",
    "    elif start_op=='&' and cur_op=='&':\n",
    "        cur_token = ('OP','AND')\n",
    "    elif start_op=='/' and cur_op=='/':\n",
    "        comment_is_set = True\n",
    "        return\n",
    "    elif start_op in list_operator and cur_op in list_operator:\n",
    "        #number_is_negative = True\n",
    "        single_char_operator(start_op)\n",
    "        single_char_operator(cur_op)\n",
    "        return\n",
    "    \n",
    "    stream_of_token.append(cur_token)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['(', ')', '[', ']', '{', '}', ';', '\"', \"'\", ',', '\\\\', '#']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_symbol = ['(',')','[',']','{','}',';','\"','\\'',',','\\\\','#']\n",
    "print(list_symbol[10])\n",
    "list_symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_symbol(symbol):\n",
    "    cur_token = ''\n",
    "    \n",
    "    if symbol=='(':\n",
    "        cur_token = ('SYMBOL','OPENING_PARENTHESES')\n",
    "    elif symbol==')':\n",
    "        cur_token = ('SYMBOL','CLOSING_PARENTHESES')\n",
    "    elif symbol=='{':\n",
    "        cur_token = ('SYMBOL','OPENING_CURLY_BRACKET')\n",
    "    elif symbol=='}':\n",
    "        cur_token = ('SYMBOL','CLOSING_CURLY_BRACKET')\n",
    "    elif symbol=='[':\n",
    "        cur_token = ('SYMBOL','OPENING_SQUARE_BRACKET')\n",
    "    elif symbol==']':\n",
    "        cur_token = ('SYMBOL','CLOSING_SQUARE_BRACKET')\n",
    "    elif symbol==';':\n",
    "        cur_token = ('SYMBOL','EOL_OR_SEPERATOR') #EOL -> End Of Line\n",
    "    elif symbol=='\"':\n",
    "        cur_token = ('SYMBOL','DOUBLE_QUOTE')\n",
    "    elif symbol=='\\'':\n",
    "        cur_token = ('SYMBOL','SINGLE_QUOTE')\n",
    "    elif symbol==',':\n",
    "        cur_token = ('SYMBOL','COMMA')\n",
    "    elif symbol=='#':\n",
    "        cur_token = ('SYMBOL','HASHTAG')\n",
    "        \n",
    "    stream_of_token.append(cur_token)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Error Check: If variable name starts with digits:\n",
    "def check_for_errors(ch):\n",
    "    global error_encountered\n",
    "    if ch in list_letter and start_char_is_digit==True:\n",
    "        print(\"Error near \",current_lexeme,'; Error No. ',list_error[0][0],'; ',list_error[0][1])\n",
    "        error_encountered = True\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def command_for_backslash(ch):\n",
    "    cur_token = ''\n",
    "    \n",
    "    if ch=='n':\n",
    "        cur_token = ('SPECIAL_COMMAND','NEWLINE')\n",
    "    elif ch=='t':\n",
    "        cur_token = ('SPECIAL_COMMAND','TAB')\n",
    "    \n",
    "    stream_of_token.append(cur_token)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_or_print_type(current_lexeme):\n",
    "    if current_lexeme=='d':\n",
    "        cur_token = ('SCAN_OR_PRINT_OF_TYPE','INTEGER')\n",
    "    elif current_lexeme=='f':\n",
    "        cur_token = ('SCAN_OR_PRINT_OF_TYPE','FLOAT')\n",
    "    elif current_lexeme=='c':\n",
    "        cur_token = ('SCAN_OR_PRINT_OF_TYPE','CHARACTER')\n",
    "    \n",
    "    stream_of_token.append(cur_token)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ckeck_start_char(ch):\n",
    "    global current_lexeme, start_char_is_digit\n",
    "    '''\n",
    "    if ch in list_special_char and current_lexeme=='':\n",
    "        start_char_is_special = True\n",
    "        current_lexeme = ch\n",
    "        return\n",
    "    '''\n",
    "    if ch in list_operator and current_lexeme=='': #If the start character is an operator...\n",
    "        #start_char_is_op = True\n",
    "        current_lexeme = ch\n",
    "        return\n",
    "    \n",
    "    if ch in list_letter and current_lexeme=='': #If the start character is a letter...\n",
    "        current_lexeme = ch\n",
    "        return\n",
    "    \n",
    "    if ch in list_digit and current_lexeme=='': #If the start character is a digit...\n",
    "        start_char_is_digit = True\n",
    "        current_lexeme = ch\n",
    "        return\n",
    "    \n",
    "    if ch in list_symbol and current_lexeme=='': #If the start character is a symbol...\n",
    "        check_symbol(ch)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = len(inputString)\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch= #\n",
      "current_lexeme=\n",
      "ch= i\n",
      "current_lexeme=\n",
      "ch= n\n",
      "current_lexeme=i\n",
      "ch= c\n",
      "current_lexeme=in\n",
      "ch= l\n",
      "current_lexeme=inc\n",
      "ch= u\n",
      "current_lexeme=incl\n",
      "ch= d\n",
      "current_lexeme=inclu\n",
      "ch= e\n",
      "current_lexeme=includ\n",
      "ch= <\n",
      "current_lexeme=include\n",
      "Token= include\n",
      "ch= s\n",
      "current_lexeme=<\n",
      "ch= t\n",
      "current_lexeme=s\n",
      "ch= d\n",
      "current_lexeme=st\n",
      "ch= i\n",
      "current_lexeme=std\n",
      "ch= o\n",
      "current_lexeme=stdi\n",
      "ch= .\n",
      "current_lexeme=stdio\n",
      "Token= stdio\n",
      "ch= h\n",
      "current_lexeme=\n",
      "ch= >\n",
      "current_lexeme=h\n",
      "Token= h\n",
      "ch= \n",
      "\n",
      "current_lexeme=>\n",
      "ch= /\n",
      "current_lexeme=\n",
      "ch= /\n",
      "current_lexeme=/\n",
      "start_op= /; cur_op= /\n",
      "ch= T\n",
      "current_lexeme=\n",
      "ch= h\n",
      "current_lexeme=\n",
      "ch= i\n",
      "current_lexeme=\n",
      "ch= s\n",
      "current_lexeme=\n",
      "ch=  \n",
      "current_lexeme=\n",
      "ch= i\n",
      "current_lexeme=\n",
      "ch= s\n",
      "current_lexeme=\n",
      "ch=  \n",
      "current_lexeme=\n",
      "ch= a\n",
      "current_lexeme=\n",
      "ch=  \n",
      "current_lexeme=\n",
      "ch= d\n",
      "current_lexeme=\n",
      "ch= e\n",
      "current_lexeme=\n",
      "ch= m\n",
      "current_lexeme=\n",
      "ch= o\n",
      "current_lexeme=\n",
      "ch=  \n",
      "current_lexeme=\n",
      "ch= c\n",
      "current_lexeme=\n",
      "ch= o\n",
      "current_lexeme=\n",
      "ch= d\n",
      "current_lexeme=\n",
      "ch= e\n",
      "current_lexeme=\n",
      "ch= :\n",
      "current_lexeme=\n",
      "ch= \n",
      "\n",
      "current_lexeme=\n",
      "ch= i\n",
      "current_lexeme=\n",
      "ch= n\n",
      "current_lexeme=i\n",
      "ch= t\n",
      "current_lexeme=in\n",
      "ch=  \n",
      "current_lexeme=int\n",
      "Token= int\n",
      "ch= m\n",
      "current_lexeme=\n",
      "ch= a\n",
      "current_lexeme=m\n",
      "ch= i\n",
      "current_lexeme=ma\n",
      "ch= n\n",
      "current_lexeme=mai\n",
      "ch= (\n",
      "current_lexeme=main\n",
      "Token= main\n",
      "ch= )\n",
      "current_lexeme=\n",
      "ch= \n",
      "\n",
      "current_lexeme=\n",
      "ch= {\n",
      "current_lexeme=\n",
      "ch= \n",
      "\n",
      "current_lexeme=\n",
      "ch=  \n",
      "current_lexeme=\n",
      "ch=  \n",
      "current_lexeme=\n",
      "ch=  \n",
      "current_lexeme=\n",
      "ch=  \n",
      "current_lexeme=\n",
      "ch= c\n",
      "current_lexeme=\n",
      "ch= h\n",
      "current_lexeme=c\n",
      "ch= a\n",
      "current_lexeme=ch\n",
      "ch= r\n",
      "current_lexeme=cha\n",
      "ch=  \n",
      "current_lexeme=char\n",
      "Token= char\n",
      "ch= s\n",
      "current_lexeme=\n",
      "ch= t\n",
      "current_lexeme=s\n",
      "ch= r\n",
      "current_lexeme=st\n",
      "ch= [\n",
      "current_lexeme=str\n",
      "Token= str\n",
      "ch= 1\n",
      "current_lexeme=\n",
      "ch= 0\n",
      "current_lexeme=1\n",
      "ch= 0\n",
      "current_lexeme=10\n",
      "ch= ]\n",
      "current_lexeme=100\n",
      "ch= ;\n",
      "current_lexeme=\n",
      "ch= \n",
      "\n",
      "current_lexeme=\n",
      "ch= \n",
      "\n",
      "current_lexeme=\n",
      "ch=  \n",
      "current_lexeme=\n",
      "ch=  \n",
      "current_lexeme=\n",
      "ch=  \n",
      "current_lexeme=\n",
      "ch=  \n",
      "current_lexeme=\n",
      "ch= g\n",
      "current_lexeme=\n",
      "ch= e\n",
      "current_lexeme=g\n",
      "ch= t\n",
      "current_lexeme=ge\n",
      "ch= s\n",
      "current_lexeme=get\n",
      "ch= (\n",
      "current_lexeme=gets\n",
      "Token= gets\n",
      "ch= s\n",
      "current_lexeme=\n",
      "ch= t\n",
      "current_lexeme=s\n",
      "ch= r\n",
      "current_lexeme=st\n",
      "ch= )\n",
      "current_lexeme=str\n",
      "Token= str\n",
      "ch= ;\n",
      "current_lexeme=\n",
      "ch= \n",
      "\n",
      "current_lexeme=\n",
      "ch= \n",
      "\n",
      "current_lexeme=\n",
      "ch=  \n",
      "current_lexeme=\n",
      "ch=  \n",
      "current_lexeme=\n",
      "ch=  \n",
      "current_lexeme=\n",
      "ch=  \n",
      "current_lexeme=\n",
      "ch= f\n",
      "current_lexeme=\n",
      "ch= o\n",
      "current_lexeme=f\n",
      "ch= r\n",
      "current_lexeme=fo\n",
      "ch= (\n",
      "current_lexeme=for\n",
      "Token= for\n",
      "ch= i\n",
      "current_lexeme=\n",
      "ch= n\n",
      "current_lexeme=i\n",
      "ch= t\n",
      "current_lexeme=in\n",
      "ch=  \n",
      "current_lexeme=int\n",
      "Token= int\n",
      "ch= i\n",
      "current_lexeme=\n",
      "ch= =\n",
      "current_lexeme=i\n",
      "Token= i\n",
      "ch= 0\n",
      "current_lexeme==\n",
      "ch= ;\n",
      "current_lexeme=0\n",
      "ch=  \n",
      "current_lexeme=\n",
      "ch= ;\n",
      "current_lexeme=\n",
      "ch= i\n",
      "current_lexeme=\n",
      "ch= +\n",
      "current_lexeme=i\n",
      "Token= i\n",
      "ch= +\n",
      "current_lexeme=+\n",
      "start_op= +; cur_op= +\n",
      "ch= )\n",
      "current_lexeme=\n",
      "ch= \n",
      "\n",
      "current_lexeme=\n",
      "ch=  \n",
      "current_lexeme=\n",
      "ch=  \n",
      "current_lexeme=\n",
      "ch=  \n",
      "current_lexeme=\n",
      "ch=  \n",
      "current_lexeme=\n",
      "ch= {\n",
      "current_lexeme=\n",
      "ch= \n",
      "\n",
      "current_lexeme=\n",
      "ch=  \n",
      "current_lexeme=\n",
      "ch=  \n",
      "current_lexeme=\n",
      "ch=  \n",
      "current_lexeme=\n",
      "ch=  \n",
      "current_lexeme=\n",
      "ch=  \n",
      "current_lexeme=\n",
      "ch=  \n",
      "current_lexeme=\n",
      "ch=  \n",
      "current_lexeme=\n",
      "ch=  \n",
      "current_lexeme=\n",
      "ch= i\n",
      "current_lexeme=\n",
      "ch= f\n",
      "current_lexeme=i\n",
      "ch= (\n",
      "current_lexeme=if\n",
      "Token= if\n",
      "ch= s\n",
      "current_lexeme=\n",
      "ch= t\n",
      "current_lexeme=s\n",
      "ch= r\n",
      "current_lexeme=st\n",
      "ch= [\n",
      "current_lexeme=str\n",
      "Token= str\n",
      "ch= i\n",
      "current_lexeme=\n",
      "ch= ]\n",
      "current_lexeme=i\n",
      "Token= i\n",
      "ch= =\n",
      "current_lexeme=\n",
      "ch= =\n",
      "current_lexeme==\n",
      "start_op= =; cur_op= =\n",
      "ch= '\n",
      "current_lexeme=\n",
      "ch= \\\n",
      "current_lexeme=\n",
      "ch= 0\n",
      "current_lexeme=\\\n",
      "ch= '\n",
      "current_lexeme=\\0\n",
      "ch= )\n",
      "current_lexeme=\n",
      "ch=  \n",
      "current_lexeme=\n",
      "ch= {\n",
      "current_lexeme=\n",
      "ch=  \n",
      "current_lexeme=\n",
      "ch= b\n",
      "current_lexeme=\n",
      "ch= r\n",
      "current_lexeme=b\n",
      "ch= e\n",
      "current_lexeme=br\n",
      "ch= a\n",
      "current_lexeme=bre\n",
      "ch= k\n",
      "current_lexeme=brea\n",
      "ch= ;\n",
      "current_lexeme=break\n",
      "Token= break\n",
      "ch=  \n",
      "current_lexeme=\n",
      "ch= }\n",
      "current_lexeme=\n",
      "ch= \n",
      "\n",
      "current_lexeme=\n",
      "ch= \n",
      "\n",
      "current_lexeme=\n",
      "ch= \n",
      "\n",
      "current_lexeme=\n",
      "ch=  \n",
      "current_lexeme=\n",
      "ch=  \n",
      "current_lexeme=\n",
      "ch=  \n",
      "current_lexeme=\n",
      "ch=  \n",
      "current_lexeme=\n",
      "ch= }\n",
      "current_lexeme=\n",
      "ch= \n",
      "\n",
      "current_lexeme=\n",
      "ch= }\n",
      "current_lexeme=\n",
      "ch= \n",
      "\n",
      "current_lexeme=\n"
     ]
    }
   ],
   "source": [
    "#Traversing through the input string:\n",
    "for ch in inputString:\n",
    "    counter -= 1\n",
    "    #print('counter=',counter)\n",
    "    print('ch= '+ch)###\n",
    "    print('current_lexeme='+current_lexeme)\n",
    "\n",
    "    if comment_is_set==True and ch=='\\n':\n",
    "        comment_is_set = False\n",
    "        continue\n",
    "    elif comment_is_set==True:\n",
    "        continue\n",
    "    \n",
    "    check_for_errors(ch)\n",
    "    if error_encountered == True:\n",
    "        error_encountered = False\n",
    "        break\n",
    "    \n",
    "    if ch=='\\\\' and current_lexeme=='': #If a 'backslash(\\)' found...\n",
    "        current_lexeme = '\\\\'\n",
    "        continue\n",
    "    if current_lexeme=='\\\\' and ch in ['n','t']: #If a backslash(\\) is followed by the list elements...\n",
    "        command_for_backslash(ch) #check command for backslash.\n",
    "        current_lexeme = ''\n",
    "        continue\n",
    "    '''\n",
    "    if ch=='%' and current_lexeme=='':\n",
    "        current_lexeme = ch\n",
    "        scan_or_print_command = True\n",
    "        continue\n",
    "    '''\n",
    "    #Start symbol checking:\n",
    "    if current_lexeme == '' and ch != ' ':\n",
    "        ckeck_start_char(ch)\n",
    "        if counter==0:\n",
    "            ch = ' '\n",
    "        else:\n",
    "            continue\n",
    "    '''\n",
    "    if current_lexeme in list_special_char and ch in list_special_letter:\n",
    "        check_special_command(current_lexeme,ch)\n",
    "        start_char_is_special = False\n",
    "        continue\n",
    "    '''\n",
    "    if scan_or_print_command==True and current_lexeme in ['d','f','c'] and ch not in list_letter:\n",
    "        scan_or_print_type(current_lexeme)\n",
    "        current_lexeme = ''\n",
    "        scan_or_print_command = False\n",
    "        if ch == ' ': #If current lexeme is terminated by space...\n",
    "            continue\n",
    "        else:\n",
    "            ckeck_start_char(ch)\n",
    "            continue\n",
    "    \n",
    "    if scan_or_print_command==True and current_lexeme in ['d','f','c'] and ch in list_letter:\n",
    "        single_char_operator('%')\n",
    "        current_lexeme += ch\n",
    "        scan_or_print_command = False\n",
    "        if counter==0:\n",
    "            ch = ' '\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    #if scan_or_print_command==True and curr\n",
    "    \n",
    "    if current_lexeme in list_operator and ch not in list_operator: #If this is a single character operator...\n",
    "        #print(\"f2\")\n",
    "        \n",
    "        if current_lexeme=='%' and ch in ['d','f','c']:\n",
    "            scan_or_print_command = True\n",
    "            current_lexeme = ch\n",
    "            continue\n",
    "        #elif ch in \n",
    "        \n",
    "        single_char_operator(current_lexeme)\n",
    "        current_lexeme = ''\n",
    "        scan_or_print_command = False\n",
    "        if ch == ' ': #If current lexeme is terminated by space...\n",
    "            continue\n",
    "        elif counter == 0:############################################################\n",
    "            ckeck_start_char(ch)\n",
    "            ch = ' '\n",
    "        else:\n",
    "            ckeck_start_char(ch)\n",
    "            continue\n",
    "        \n",
    "    if current_lexeme in list_operator and ch in list_operator: #If this is a double character operator...\n",
    "        #print(\"f1\")\n",
    "        double_char_operator(current_lexeme,ch)\n",
    "        current_lexeme = ''\n",
    "        continue\n",
    "    \n",
    "    #If the current character is a letter or digit, and is not the start character of the lexeme:\n",
    "    if ch in list_digit or ch in list_letter: \n",
    "        current_lexeme += ch\n",
    "        if counter == 0 and scan_or_print_command==True: #If ch is the last element...\n",
    "            single_char_operator('%')\n",
    "            scan_or_print_command = False\n",
    "            ch = ' '\n",
    "        elif counter == 0:\n",
    "            ch = ' '\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "    if (ch not in list_letter and ch not in list_digit) and start_char_is_digit==False: #If the lexeme is either a keyword or an identifier...\n",
    "        #if \n",
    "        if current_lexeme=='\\\\0':\n",
    "            stream_of_token.append(('KEYWORD','NULL'))\n",
    "        elif current_lexeme is not '':\n",
    "            check_if_reserved_word(current_lexeme) #Check if the current lexeme is a keyword or an identifier.\n",
    "        \n",
    "        current_lexeme = ''\n",
    "        if ch=='.':\n",
    "            stream_of_token.append(('SYMBOL','DOT'))\n",
    "        elif ch is not ' ': #If current lexeme is terminated by space...\n",
    "            ckeck_start_char(ch) \n",
    "        continue\n",
    "        #else if current lexeme is not terminated by space, continue operations on current character...\n",
    "    \n",
    "    if ch=='.' and start_char_is_digit==True: #If the floating point symbol(.) is found in current 'number' type lexeme...\n",
    "        number_is_float = True\n",
    "        current_lexeme += ch\n",
    "        continue\n",
    "    \n",
    "    if (ch not in list_letter and ch not in list_digit) and start_char_is_digit==True: #If the lexeme is a number...\n",
    "        start_char_is_digit = False\n",
    "        \n",
    "        if current_lexeme is not '':\n",
    "            if number_is_negative is True:\n",
    "                #current_lexeme = '-'+current_lexeme #Negating current number.\n",
    "                cur_token = ('OP','NEGATIVE')\n",
    "                stream_of_token.append(cur_token)\n",
    "                \n",
    "            if number_is_float==False: #If the number is a floating point...\n",
    "                cur_token = ('INTEGER',current_lexeme)\n",
    "                stream_of_token.append(cur_token)\n",
    "            else: #If the number is an integer...\n",
    "                number_is_float = False\n",
    "                cur_token = ('FLOAT',current_lexeme)\n",
    "                stream_of_token.append(cur_token)\n",
    "        \n",
    "        current_lexeme = ''\n",
    "        if ch is not ' ': #If current lexeme is terminated by space...\n",
    "            ckeck_start_char(ch)\n",
    "        continue\n",
    "        #else if current lexeme is not terminated by space, continue operations on current character..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#include<stdio.h>\n",
      "//This is a demo code:\n",
      "int main()\n",
      "{\n",
      "    char str[100];\n",
      "\n",
      "    gets(str);\n",
      "\n",
      "    for(int i=0; ;i++)\n",
      "    {\n",
      "        if(str[i]=='\\0') { break; }\n",
      "\n",
      "\n",
      "    }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"#include<stdio.h>\\n//This is a demo code:\\nint main()\\n{\\n    char str[100];\\n\\n    gets(str);\\n\\n    for(int i=0; ;i++)\\n    {\\n        if(str[i]=='\\\\0') { break; }\\n\\n\\n    }\\n}\\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(inputString)\n",
    "inputString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'stdio'), (2, 'h'), (3, 'str'), (4, 'i')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SYMBOL', 'HASHTAG'),\n",
       " ('KEYWORD', 'include'),\n",
       " ('OP', 'LESS_THAN'),\n",
       " ('id', 1),\n",
       " ('SYMBOL', 'DOT'),\n",
       " ('id', 2),\n",
       " ('OP', 'GREATER_THAN'),\n",
       " ('KEYWORD', 'int'),\n",
       " ('KEYWORD', 'main'),\n",
       " ('SYMBOL', 'OPENING_PARENTHESES'),\n",
       " ('SYMBOL', 'CLOSING_PARENTHESES'),\n",
       " ('SYMBOL', 'OPENING_CURLY_BRACKET'),\n",
       " ('KEYWORD', 'char'),\n",
       " ('id', 3),\n",
       " ('SYMBOL', 'OPENING_SQUARE_BRACKET'),\n",
       " ('INTEGER', '100'),\n",
       " ('SYMBOL', 'CLOSING_SQUARE_BRACKET'),\n",
       " ('SYMBOL', 'EOL_OR_SEPERATOR'),\n",
       " ('KEYWORD', 'gets'),\n",
       " ('SYMBOL', 'OPENING_PARENTHESES'),\n",
       " ('id', 3),\n",
       " ('SYMBOL', 'CLOSING_PARENTHESES'),\n",
       " ('SYMBOL', 'EOL_OR_SEPERATOR'),\n",
       " ('KEYWORD', 'for'),\n",
       " ('SYMBOL', 'OPENING_PARENTHESES'),\n",
       " ('KEYWORD', 'int'),\n",
       " ('id', 4),\n",
       " ('OP', 'ASSIGN'),\n",
       " ('INTEGER', '0'),\n",
       " ('SYMBOL', 'EOL_OR_SEPERATOR'),\n",
       " ('SYMBOL', 'EOL_OR_SEPERATOR'),\n",
       " ('id', 4),\n",
       " ('OP', 'INCREAMENT'),\n",
       " ('SYMBOL', 'CLOSING_PARENTHESES'),\n",
       " ('SYMBOL', 'OPENING_CURLY_BRACKET'),\n",
       " ('KEYWORD', 'if'),\n",
       " ('SYMBOL', 'OPENING_PARENTHESES'),\n",
       " ('id', 3),\n",
       " ('SYMBOL', 'OPENING_SQUARE_BRACKET'),\n",
       " ('id', 4),\n",
       " ('SYMBOL', 'CLOSING_SQUARE_BRACKET'),\n",
       " ('OP', 'EQUAL'),\n",
       " ('SYMBOL', 'SINGLE_QUOTE'),\n",
       " ('KEYWORD', 'NULL'),\n",
       " ('SYMBOL', 'SINGLE_QUOTE'),\n",
       " ('SYMBOL', 'CLOSING_PARENTHESES'),\n",
       " ('SYMBOL', 'OPENING_CURLY_BRACKET'),\n",
       " ('KEYWORD', 'break'),\n",
       " ('SYMBOL', 'EOL_OR_SEPERATOR'),\n",
       " ('SYMBOL', 'CLOSING_CURLY_BRACKET'),\n",
       " ('SYMBOL', 'CLOSING_CURLY_BRACKET'),\n",
       " ('SYMBOL', 'CLOSING_CURLY_BRACKET')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream_of_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
